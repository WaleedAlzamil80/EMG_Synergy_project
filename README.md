# Finger Angle Prediction from EMG and Accelerometer Data:

This project aims to predict the angles of 14 fingers from electromyography (EMG) and accelerometer (ACC) data collected from two subjects performing different hand gestures. The data is obtained from the NinaPro database, which contains recordings of surface EMG signals and inertial measurement units (IMU) from 40 intact subjects and 11 transradial amputees.

## Data Description

we will use Data Citations 2
The data consists of six files in MATLAB format: E1.mat and E2.mat for the EMG and ACC data, and glove1.mat and glove2.mat for the glove data. The glove data contains the angles of 22 sensors attached to a CyberGlove II device worn by the subjects. The stimulus1.mat and stimulus2.mat files contain the information about the hand gestures performed by the subjects.

The data is preprocessed using Pandas, Numpy, and Scipy libraries to extract the relevant features and normalize them. The glove data is converted to finger angles using a predefined array of maximum angles for each sensor. The finger angles are used as the target variable for the prediction task, while the EMG and ACC data are used as the input variable.

NOTE: At this stage I'll only use EMG as the input after this we can add also the ACC and see if it's significant and worth it.

## Model Description

The model is built using PyTorch, a popular deep learning framework that provides high-level APIs for creating neural networks. The model consists of eight linear layers with ReLU activation functions. The model takes the EMG and ACC data as input and generates the finger angles as output.

The linear layers are fully connected layers that perform a linear transformation on the input. The ReLU activation function is a non-linear function that returns the input if it is positive, and zero otherwise. The ReLU function helps to introduce non-linearity and avoid the vanishing gradient problem in the model.

### The model has the following architecture:

- The first layer has 12 input features and 128 output features.
- The second layer has 128 input features and 256 output features.
- The third layer has 256 input features and 1024 output features.
- The fourth layer has 1024 input features and 4096 output features.
- The fifth layer has 4096 input features and 4096 output features.
- The sixth layer has 4096 input features and 2048 output features.
- The seventh layer has 2048 input features and 512 output features.
- The eighth layer has 512 input features and 14 output features.

#### The model is trained using a constant learning rate and a fixed number of epochs. The loss function used is the mean squared error (MSE) loss, which measures the difference between the predicted values and the true values. The optimizer used is Adam, which is an adaptive gradient-based algorithm that updates the parameters based on the gradients of the loss function.

## How to Use

To use this model, you need to have Python 3 installed on your system, along with PyTorch, HuggingFace Transformers (for future), Pandas, Numpy, and Scipy libraries. You also need to download the data files from the NinaPro website or use the links provided in this repository or through the links in the notebook

To use this model, you need to execute the following steps:

- Clone or download this repository to your local machine.
- Navigate to the folder where you saved this repository using a terminal or command prompt.
- Run all the cells in the Synergy_EMG.ipynb.
- Wait for the model to train and evaluate on the data.
- Check the results and plots generated by the project.

NOTE: in future work I will push the best model to the Huggingface for the ease of using the trained model

## Suggestions for Future work:

- Experiment with different model architectures, such as convolutional neural networks (CNNs) or recurrent neural networks (RNNs), and see how they affect the performance.
- Use a different loss function, such as mean absolute error (MAE) or mean squared logarithmic error (MSLE), and compare the results with MSE.
- Plot the loss curves for the training and test data and analyze how the model converges over time.
- Visualize the predicted finger angles and compare them with the true finger angles using matplotlib or seaborn libraries.

- What I'm looking to do ðŸ˜Š is to Build a model using PyTorch, a popular deep learning framework that provides high-level APIs for creating neural networks. The model consists of a HuggingFace ðŸ˜Š Transformers model, such as AutoModelForSeq2SeqLM, followed by two linear layers with dropout. The model will also take the EMG and ACC data as input and generates the finger angles as output.The model will be trained using a constant learning rate and a fixed number of epochs. The loss function used will be used is the mean-squared error loss, which measures the square of the difference between the predicted values and the actual values. The optimizer which will be used is Adam, which is an adaptive gradient-based algorithm that updates the parameters based on the gradients of the loss function.

## References
[NinaPro Database](http://ninapro.hevs.ch/)
